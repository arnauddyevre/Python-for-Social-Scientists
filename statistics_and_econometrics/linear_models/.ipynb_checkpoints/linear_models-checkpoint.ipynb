{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models\n",
    "\n",
    "*Friday, September 20*\n",
    "\n",
    "### Content\n",
    "\n",
    "- [1. The statsmodel package](#1.-The-statsmodels-package)\n",
    "- [2. OLS](#2.-OLS)\n",
    "- [3. Generalised linear model](#3.-Generalised-linear-model)\n",
    "- [4. Two-stage least squares](#4.-Two-stage-least-squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The statsmodels package\n",
    "\n",
    "_`statsmodels` is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration._\n",
    "\n",
    "The online documentation is hosted at [statsmodels.org](https://www.statsmodels.org/stable/index.html)\n",
    "\n",
    "It covered:\n",
    "\n",
    "- Linear Regression \n",
    "- Generalized Linear Models \n",
    "- Generalized Estimating Equations \n",
    "- Generalized Additive Models (GAM) \n",
    "- Robust Linear Models \n",
    "- Linear Mixed Effects Models \n",
    "- Regression with Discrete Dependent Variable \n",
    "- Generalized Linear Mixed Effects Models \n",
    "- ANOVA \n",
    "- Time Series analysis `tsa` \n",
    "- Time Series Analysis by State Space Methods statespace \n",
    "- Vector Autoregressions `tsa.vector_ar` \n",
    "- Methods for Survival and Duration Analysis \n",
    "- Statistics `stats` \n",
    "- Nonparametric Methods nonparametric \n",
    "- Generalized Method of Moments `gmm` \n",
    "- Contingency tables \n",
    "- Multiple Imputation with Chained Equations \n",
    "- Multivariate Statistics multivariate \n",
    "- Empirical Likelihood emplike \n",
    "- Other Models miscmodels \n",
    "- Distributions \n",
    "- Graphics \n",
    "- Input-Output iolib \n",
    "- Tools \n",
    "- The Datasets Package \n",
    "- Sandbox \n",
    "- Working with Large Data Sets \n",
    "- Optimization\n",
    "\n",
    "`statsmodels` works smoothly with the `pandas` in a way that DataFrame is the dataset form it supports by default.\n",
    "\n",
    "Anaconda has installed `statsmodels` module by default.\n",
    "Before using the functions and classes inside, we need to import the `statsmodels.api` and `statsmodels.formula.api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `statsmodels` is similiar to the output of functions in `R`.\n",
    "We start with the most widely used and elementary statistical methods : ordinary least square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. How to fit a dataset and see the result**\n",
    "\n",
    "We use the dataset `Guerry` provided by `statsmodel` which studied the determinants of the number of lottery sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>Region</th>\n",
       "      <th>Department</th>\n",
       "      <th>Crime_pers</th>\n",
       "      <th>Crime_prop</th>\n",
       "      <th>Literacy</th>\n",
       "      <th>Donations</th>\n",
       "      <th>Infants</th>\n",
       "      <th>Suicides</th>\n",
       "      <th>MainCity</th>\n",
       "      <th>...</th>\n",
       "      <th>Crime_parents</th>\n",
       "      <th>Infanticide</th>\n",
       "      <th>Donation_clergy</th>\n",
       "      <th>Lottery</th>\n",
       "      <th>Desertion</th>\n",
       "      <th>Instruction</th>\n",
       "      <th>Prostitutes</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Area</th>\n",
       "      <th>Pop1831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>Ain</td>\n",
       "      <td>28870</td>\n",
       "      <td>15890</td>\n",
       "      <td>37</td>\n",
       "      <td>5098</td>\n",
       "      <td>33120</td>\n",
       "      <td>35039</td>\n",
       "      <td>2:Med</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>41</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>218.372</td>\n",
       "      <td>5762</td>\n",
       "      <td>346.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>26226</td>\n",
       "      <td>5521</td>\n",
       "      <td>51</td>\n",
       "      <td>8901</td>\n",
       "      <td>14572</td>\n",
       "      <td>12831</td>\n",
       "      <td>2:Med</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>327</td>\n",
       "      <td>65.945</td>\n",
       "      <td>7369</td>\n",
       "      <td>513.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>Allier</td>\n",
       "      <td>26747</td>\n",
       "      <td>7925</td>\n",
       "      <td>13</td>\n",
       "      <td>10973</td>\n",
       "      <td>17044</td>\n",
       "      <td>114121</td>\n",
       "      <td>2:Med</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>76</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>85</td>\n",
       "      <td>34</td>\n",
       "      <td>161.927</td>\n",
       "      <td>7340</td>\n",
       "      <td>298.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>Basses-Alpes</td>\n",
       "      <td>12935</td>\n",
       "      <td>7289</td>\n",
       "      <td>46</td>\n",
       "      <td>2733</td>\n",
       "      <td>23018</td>\n",
       "      <td>14238</td>\n",
       "      <td>1:Sm</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>351.399</td>\n",
       "      <td>6925</td>\n",
       "      <td>155.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>17488</td>\n",
       "      <td>8174</td>\n",
       "      <td>69</td>\n",
       "      <td>6962</td>\n",
       "      <td>23076</td>\n",
       "      <td>16171</td>\n",
       "      <td>1:Sm</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>320.280</td>\n",
       "      <td>5549</td>\n",
       "      <td>129.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dept Region    Department  Crime_pers  Crime_prop  Literacy  Donations  \\\n",
       "0     1      E           Ain       28870       15890        37       5098   \n",
       "1     2      N         Aisne       26226        5521        51       8901   \n",
       "2     3      C        Allier       26747        7925        13      10973   \n",
       "3     4      E  Basses-Alpes       12935        7289        46       2733   \n",
       "4     5      E  Hautes-Alpes       17488        8174        69       6962   \n",
       "\n",
       "   Infants  Suicides MainCity  ...  Crime_parents  Infanticide  \\\n",
       "0    33120     35039    2:Med  ...             71           60   \n",
       "1    14572     12831    2:Med  ...              4           82   \n",
       "2    17044    114121    2:Med  ...             46           42   \n",
       "3    23018     14238     1:Sm  ...             70           12   \n",
       "4    23076     16171     1:Sm  ...             22           23   \n",
       "\n",
       "   Donation_clergy  Lottery  Desertion  Instruction  Prostitutes  Distance  \\\n",
       "0               69       41         55           46           13   218.372   \n",
       "1               36       38         82           24          327    65.945   \n",
       "2               76       66         16           85           34   161.927   \n",
       "3               37       80         32           29            2   351.399   \n",
       "4               64       79         35            7            1   320.280   \n",
       "\n",
       "   Area  Pop1831  \n",
       "0  5762   346.03  \n",
       "1  7369   513.00  \n",
       "2  7340   298.26  \n",
       "3  6925   155.90  \n",
       "4  5549   129.10  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load data\n",
    "dat = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data\n",
    "# list of the variables\n",
    "dat.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, we studied the relationship between lottery and the literacy and population (in the log scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model (using the natural log of one of the regressors)\n",
    "model = smf.ols('Lottery ~ Literacy + np.log(Pop1831)', data=dat)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the results, we need an additional step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Lottery   R-squared:                       0.348\n",
      "Model:                            OLS   Adj. R-squared:                  0.333\n",
      "Method:                 Least Squares   F-statistic:                     22.20\n",
      "Date:                Thu, 12 Sep 2019   Prob (F-statistic):           1.90e-08\n",
      "Time:                        22:19:49   Log-Likelihood:                -379.82\n",
      "No. Observations:                  86   AIC:                             765.6\n",
      "Df Residuals:                      83   BIC:                             773.0\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept         246.4341     35.233      6.995      0.000     176.358     316.510\n",
      "Literacy           -0.4889      0.128     -3.832      0.000      -0.743      -0.235\n",
      "np.log(Pop1831)   -31.3114      5.977     -5.239      0.000     -43.199     -19.424\n",
      "==============================================================================\n",
      "Omnibus:                        3.713   Durbin-Watson:                   2.019\n",
      "Prob(Omnibus):                  0.156   Jarque-Bera (JB):                3.394\n",
      "Skew:                          -0.487   Prob(JB):                        0.183\n",
      "Kurtosis:                       3.003   Cond. No.                         702.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. When the dataset is not in `DataFrame`**\n",
    "\n",
    "The dataset above is provided by `statsmodels` package hence in the form it supports. \n",
    "However, in many situations, the dataset is not constructed yet. \n",
    "In this case, we can use `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.164\n",
      "Model:                            OLS   Adj. R-squared:                  0.146\n",
      "Method:                 Least Squares   F-statistic:                     9.495\n",
      "Date:                Thu, 12 Sep 2019   Prob (F-statistic):           0.000171\n",
      "Time:                        22:19:50   Log-Likelihood:                -10.743\n",
      "No. Observations:                 100   AIC:                             27.49\n",
      "Df Residuals:                      97   BIC:                             35.30\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.6012      0.076     21.023      0.000       1.450       1.752\n",
      "x1            -0.0612      0.099     -0.619      0.538      -0.257       0.135\n",
      "x2             0.4040      0.097      4.183      0.000       0.212       0.596\n",
      "==============================================================================\n",
      "Omnibus:                       11.587   Durbin-Watson:                   1.954\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):                4.146\n",
      "Skew:                           0.156   Prob(JB):                        0.126\n",
      "Kurtosis:                       2.053   Cond. No.                         5.67\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate artificial data (2 regressors + constant)\n",
    "nobs = 100\n",
    "\n",
    "X = np.random.random((nobs, 2))\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "beta = [1, .1, .5]\n",
    "\n",
    "e = np.random.random(nobs)\n",
    "\n",
    "y = np.dot(X, beta) + e\n",
    "\n",
    "# Fit regression model\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "# Inspect the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can create a dataset and make it supported by `statsmodels`.\n",
    "Details can be found here: [adding a dataset](https://www.statsmodels.org/stable/dev/dataset_notes.html?highlight=statsmodels%20datasets#adding-a-dataset-an-example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3. Wald's test**\n",
    "\n",
    "Besides the fitting, `statsmodels` also supports many statsitical testing methods.\n",
    "Here, we show how to use _Wald's test_ in `statsmodels`. \n",
    "\n",
    "Again, we consider the  dataset `Guerry`.\n",
    "\n",
    "We want to analyse the effect of _Wealth_ and _Literacy_ on the _Crime_pers_ and test:\n",
    "\n",
    "> whether the coeffcients of _Wealth_ and _Literacy_ are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=array([[0.03467668]]), p=0.8527291641569565, df_denom=83, df_num=1>\n"
     ]
    }
   ],
   "source": [
    "formula = 'Crime_pers ~ Wealth + Literacy'\n",
    "results = smf.ols(formula, dat).fit()\n",
    "hypotheses = '(Wealth = Literacy)'\n",
    "f_test = results.f_test(hypotheses)\n",
    "print(f_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generalised linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized linear models in `statsmodels` currently supports estimation using the one-parameter exponential families.\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "The statistical model for each observation $i$ is assumed to be\n",
    "\n",
    " $Y_i \\sim F_{EDM}(\\cdot|\\theta,\\phi,w_i)$ and\n",
    " $\\mu_i = E[Y_i|x_i] = g^{-1}(x_i^\\prime\\beta)$.\n",
    "\n",
    "where $g$ is the link function and $F_{EDM}(\\cdot|\\theta,\\phi,w)$\n",
    "is a distribution of the family of exponential dispersion models (EDM) with\n",
    "natural parameter $\\theta$, scale parameter $\\phi$ and weight\n",
    ":math:`w`.\n",
    "Its density is given by\n",
    "\n",
    " $$f_{EDM}(y|\\theta,\\phi,w) = c(y,\\phi,w)\n",
    " \\exp\\left(\\frac{y\\theta-b(\\theta)}{\\phi}w\\right)\\,.$$\n",
    "\n",
    "It follows that $\\mu = b'(\\theta)$ and\n",
    "$Var[Y|x]=\\frac{\\phi}{w}b''(\\theta)$. The inverse of the first equation\n",
    "gives the natural parameter as a function of the expected value\n",
    "$\\theta(\\mu)$ such that\n",
    "\n",
    " $$Var[Y_i|x_i] = \\frac{\\phi}{w_i} v(\\mu_i)$$\n",
    "\n",
    "with $v(\\mu) = b''(\\theta(\\mu))$. Therefore it is said that a GLM is\n",
    "determined by link function $g$ and variance function $v(\\mu)$\n",
    "alone (and $x$ of course).\n",
    "\n",
    "Note that while $\\phi$ is the same for every observation $y_i$\n",
    "and therefore does not influence the estimation of $\\beta$,\n",
    "the weights $w_i$ might be different for every $y_i$ such that the\n",
    "estimation of $\\beta$ depends on them.\n",
    "\n",
    "**Examples: binomial response $B(n,p)$**\n",
    "\n",
    "$\\mu=E[Y|x] = np$                    \n",
    "$v(\\mu) = \\mu-\\frac{\\mu^2}{n}$             \n",
    "$ \\theta(\\mu) = \\log\\frac{p}{1-p}$                 \n",
    "$b(\\theta) = n\\log(1+e^\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real  data**\n",
    "\n",
    "Here we use the Star98 dataset which was taken with permission from Jeff Gill (2000) _Generalized linear models: A unified approach_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NABOVE</th>\n",
       "      <th>NBELOW</th>\n",
       "      <th>LOWINC</th>\n",
       "      <th>PERASIAN</th>\n",
       "      <th>PERBLACK</th>\n",
       "      <th>PERHISP</th>\n",
       "      <th>PERMINTE</th>\n",
       "      <th>AVYRSEXP</th>\n",
       "      <th>AVSALK</th>\n",
       "      <th>PERSPENK</th>\n",
       "      <th>...</th>\n",
       "      <th>PCTCHRT</th>\n",
       "      <th>PCTYRRND</th>\n",
       "      <th>PERMINTE_AVYRSEXP</th>\n",
       "      <th>PERMINTE_AVSAL</th>\n",
       "      <th>AVYRSEXP_AVSAL</th>\n",
       "      <th>PERSPEN_PTRATIO</th>\n",
       "      <th>PERSPEN_PCTAF</th>\n",
       "      <th>PTRATIO_PCTAF</th>\n",
       "      <th>PERMINTE_AVYRSEXP_AVSAL</th>\n",
       "      <th>PERSPEN_PTRATIO_PCTAF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>34.39730</td>\n",
       "      <td>23.299300</td>\n",
       "      <td>14.235280</td>\n",
       "      <td>11.411120</td>\n",
       "      <td>15.91837</td>\n",
       "      <td>14.70646</td>\n",
       "      <td>59.15732</td>\n",
       "      <td>4.445207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.222220</td>\n",
       "      <td>234.102872</td>\n",
       "      <td>941.68811</td>\n",
       "      <td>869.9948</td>\n",
       "      <td>96.50656</td>\n",
       "      <td>253.52242</td>\n",
       "      <td>1238.1955</td>\n",
       "      <td>13848.8985</td>\n",
       "      <td>5504.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.36507</td>\n",
       "      <td>29.328380</td>\n",
       "      <td>8.234897</td>\n",
       "      <td>9.314884</td>\n",
       "      <td>13.63636</td>\n",
       "      <td>16.08324</td>\n",
       "      <td>59.50397</td>\n",
       "      <td>5.267598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.316851</td>\n",
       "      <td>811.41756</td>\n",
       "      <td>957.0166</td>\n",
       "      <td>107.68435</td>\n",
       "      <td>340.40609</td>\n",
       "      <td>1321.0664</td>\n",
       "      <td>13050.2233</td>\n",
       "      <td>6958.8468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>32.64324</td>\n",
       "      <td>9.226386</td>\n",
       "      <td>42.406310</td>\n",
       "      <td>13.543720</td>\n",
       "      <td>28.83436</td>\n",
       "      <td>14.59559</td>\n",
       "      <td>60.56992</td>\n",
       "      <td>5.482922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.854496</td>\n",
       "      <td>1746.49488</td>\n",
       "      <td>884.0537</td>\n",
       "      <td>103.92435</td>\n",
       "      <td>295.75929</td>\n",
       "      <td>1022.4252</td>\n",
       "      <td>25491.1232</td>\n",
       "      <td>5605.8777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>395.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>11.90953</td>\n",
       "      <td>13.883090</td>\n",
       "      <td>3.796973</td>\n",
       "      <td>11.443110</td>\n",
       "      <td>11.11111</td>\n",
       "      <td>14.38939</td>\n",
       "      <td>58.33411</td>\n",
       "      <td>4.165093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>159.882095</td>\n",
       "      <td>648.15671</td>\n",
       "      <td>839.3923</td>\n",
       "      <td>90.11341</td>\n",
       "      <td>204.34375</td>\n",
       "      <td>1061.4545</td>\n",
       "      <td>9326.5797</td>\n",
       "      <td>4421.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>36.88889</td>\n",
       "      <td>12.187500</td>\n",
       "      <td>76.875000</td>\n",
       "      <td>7.604167</td>\n",
       "      <td>43.58974</td>\n",
       "      <td>13.90568</td>\n",
       "      <td>63.15364</td>\n",
       "      <td>4.324902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>606.144976</td>\n",
       "      <td>2752.85075</td>\n",
       "      <td>878.1943</td>\n",
       "      <td>81.22097</td>\n",
       "      <td>226.54248</td>\n",
       "      <td>983.7059</td>\n",
       "      <td>38280.2616</td>\n",
       "      <td>4254.4314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NABOVE  NBELOW    LOWINC   PERASIAN   PERBLACK    PERHISP  PERMINTE  \\\n",
       "0   452.0   355.0  34.39730  23.299300  14.235280  11.411120  15.91837   \n",
       "1   144.0    40.0  17.36507  29.328380   8.234897   9.314884  13.63636   \n",
       "2   337.0   234.0  32.64324   9.226386  42.406310  13.543720  28.83436   \n",
       "3   395.0   178.0  11.90953  13.883090   3.796973  11.443110  11.11111   \n",
       "4     8.0    57.0  36.88889  12.187500  76.875000   7.604167  43.58974   \n",
       "\n",
       "   AVYRSEXP    AVSALK  PERSPENK  ...  PCTCHRT   PCTYRRND  PERMINTE_AVYRSEXP  \\\n",
       "0  14.70646  59.15732  4.445207  ...      0.0  22.222220         234.102872   \n",
       "1  16.08324  59.50397  5.267598  ...      0.0   0.000000         219.316851   \n",
       "2  14.59559  60.56992  5.482922  ...      0.0   0.000000         420.854496   \n",
       "3  14.38939  58.33411  4.165093  ...      0.0   7.142857         159.882095   \n",
       "4  13.90568  63.15364  4.324902  ...      0.0   0.000000         606.144976   \n",
       "\n",
       "   PERMINTE_AVSAL  AVYRSEXP_AVSAL  PERSPEN_PTRATIO  PERSPEN_PCTAF  \\\n",
       "0       941.68811        869.9948         96.50656      253.52242   \n",
       "1       811.41756        957.0166        107.68435      340.40609   \n",
       "2      1746.49488        884.0537        103.92435      295.75929   \n",
       "3       648.15671        839.3923         90.11341      204.34375   \n",
       "4      2752.85075        878.1943         81.22097      226.54248   \n",
       "\n",
       "   PTRATIO_PCTAF  PERMINTE_AVYRSEXP_AVSAL  PERSPEN_PTRATIO_PCTAF  \n",
       "0      1238.1955               13848.8985              5504.0352  \n",
       "1      1321.0664               13050.2233              6958.8468  \n",
       "2      1022.4252               25491.1232              5605.8777  \n",
       "3      1061.4545                9326.5797              4421.0568  \n",
       "4       983.7059               38280.2616              4254.4314  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "star98 = sm.datasets.star98.load(as_pandas=True)\n",
    "star98.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::\n",
      "\n",
      "    Number of Observations - 303 (counties in California).\n",
      "\n",
      "    Number of Variables - 13 and 8 interaction terms.\n",
      "\n",
      "    Definition of variables names::\n",
      "\n",
      "        NABOVE   - Total number of students above the national median for the\n",
      "                   math section.\n",
      "        NBELOW   - Total number of students below the national median for the\n",
      "                   math section.\n",
      "        LOWINC   - Percentage of low income students\n",
      "        PERASIAN - Percentage of Asian student\n",
      "        PERBLACK - Percentage of black students\n",
      "        PERHISP  - Percentage of Hispanic students\n",
      "        PERMINTE - Percentage of minority teachers\n",
      "        AVYRSEXP - Sum of teachers' years in educational service divided by the\n",
      "                number of teachers.\n",
      "        AVSALK   - Total salary budget including benefits divided by the number\n",
      "                   of full-time teachers (in thousands)\n",
      "        PERSPENK - Per-pupil spending (in thousands)\n",
      "        PTRATIO  - Pupil-teacher ratio.\n",
      "        PCTAF    - Percentage of students taking UC/CSU prep courses\n",
      "        PCTCHRT  - Percentage of charter schools\n",
      "        PCTYRRND - Percentage of year-round schools\n",
      "\n",
      "        The below variables are interaction terms of the variables defined\n",
      "        above.\n",
      "\n",
      "        PERMINTE_AVYRSEXP\n",
      "        PEMINTE_AVSAL\n",
      "        AVYRSEXP_AVSAL\n",
      "        PERSPEN_PTRATIO\n",
      "        PERSPEN_PCTAF\n",
      "        PTRATIO_PCTAF\n",
      "        PERMINTE_AVTRSEXP_AVSAL\n",
      "        PERSPEN_PTRATIO_PCTAF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sm.datasets.star98.NOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use genelized linear model to analyze the number of students above the national median for the math section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:           ['y1', 'y2']   No. Observations:                  303\n",
      "Model:                            GLM   Df Residuals:                      282\n",
      "Model Family:                Binomial   Df Model:                           20\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2998.6\n",
      "Date:                Thu, 12 Sep 2019   Deviance:                       4078.8\n",
      "Time:                        22:19:56   Pearson chi2:                 4.05e+03\n",
      "No. Iterations:                     5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0168      0.000    -38.749      0.000      -0.018      -0.016\n",
      "x2             0.0099      0.001     16.505      0.000       0.009       0.011\n",
      "x3            -0.0187      0.001    -25.182      0.000      -0.020      -0.017\n",
      "x4            -0.0142      0.000    -32.818      0.000      -0.015      -0.013\n",
      "x5             0.2545      0.030      8.498      0.000       0.196       0.313\n",
      "x6             0.2407      0.057      4.212      0.000       0.129       0.353\n",
      "x7             0.0804      0.014      5.775      0.000       0.053       0.108\n",
      "x8            -1.9522      0.317     -6.162      0.000      -2.573      -1.331\n",
      "x9            -0.3341      0.061     -5.453      0.000      -0.454      -0.214\n",
      "x10           -0.1690      0.033     -5.169      0.000      -0.233      -0.105\n",
      "x11            0.0049      0.001      3.921      0.000       0.002       0.007\n",
      "x12           -0.0036      0.000    -15.878      0.000      -0.004      -0.003\n",
      "x13           -0.0141      0.002     -7.391      0.000      -0.018      -0.010\n",
      "x14           -0.0040      0.000     -8.450      0.000      -0.005      -0.003\n",
      "x15           -0.0039      0.001     -4.059      0.000      -0.006      -0.002\n",
      "x16            0.0917      0.015      6.321      0.000       0.063       0.120\n",
      "x17            0.0490      0.007      6.574      0.000       0.034       0.064\n",
      "x18            0.0080      0.001      5.362      0.000       0.005       0.011\n",
      "x19            0.0002   2.99e-05      7.428      0.000       0.000       0.000\n",
      "x20           -0.0022      0.000     -6.445      0.000      -0.003      -0.002\n",
      "const          2.9589      1.547      1.913      0.056      -0.073       5.990\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "data = sm.datasets.star98.load(as_pandas=False)\n",
    "data.exog = sm.add_constant(data.exog, prepend=False)\n",
    "glm_binom = sm.GLM(data.endog, data.exog, family=sm.families.Binomial())\n",
    "res = glm_binom.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can see the fit plot of the glm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = res.nobs\n",
    "y = data.endog[:,0]/data.endog.sum(1)\n",
    "yhat = res.mu\n",
    "\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(yhat, y)\n",
    "line_fit = sm.OLS(y, sm.add_constant(yhat, prepend=True)).fit()\n",
    "abline_plot(model_results=line_fit, ax=ax)\n",
    "\n",
    "\n",
    "ax.set_title('Model Fit Plot')\n",
    "ax.set_ylabel('Observed values')\n",
    "ax.set_xlabel('Fitted values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Two-stage least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1. Endogeneity**\n",
    "\n",
    "Endogeneity issues are at the central of the quantitative research in the social science.\n",
    "That is to say, when we use the linear regression, the dependent variable might actually affect the explaintionary variable.\n",
    "And once this happens, the estimates from the OLS could be largely biased.\n",
    "\n",
    "For example, there is a two-way relationship between the institutions and the economic outcomes:\n",
    "\n",
    "- better institutions will output labor force of higher quality which boost the economic development\n",
    "- richer countries/cities can afford better institutions\n",
    "\n",
    "To eliminate such endogeneity, two-stage least square method is one tool used by many social scientists.\n",
    "The idea is to find an _instrument variable_ that is\n",
    "\n",
    "- correlated with the explaintionary variable\n",
    "- not correlated with the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2. Real data: Acemoglu et al. (2001)**\n",
    "\n",
    "As an example, we will use the data set from Daron Acemoglu, Simon Johnson, and James A Robinson. _The colonial origins of comparative development: an empirical investigation_. The American Economic Review, 91(5):1369–1401, 2001.\n",
    "\n",
    "In this paper, Acemoglu et al. (2001) want to study the effect of the institution quality on the economic outcomes.\n",
    "\n",
    "The data set could be downloaded from [Quant Econ](https://lectures.quantecon.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortnam</th>\n",
       "      <th>africa</th>\n",
       "      <th>lat_abst</th>\n",
       "      <th>rich4</th>\n",
       "      <th>avexpr</th>\n",
       "      <th>logpgp95</th>\n",
       "      <th>logem4</th>\n",
       "      <th>asia</th>\n",
       "      <th>loghjypl</th>\n",
       "      <th>baseco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>7.770645</td>\n",
       "      <td>5.634789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.411248</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.386364</td>\n",
       "      <td>9.133459</td>\n",
       "      <td>4.232656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.872274</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.318182</td>\n",
       "      <td>9.897972</td>\n",
       "      <td>2.145931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.170788</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BFA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.454545</td>\n",
       "      <td>6.845880</td>\n",
       "      <td>5.634789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.540459</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BGD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.136364</td>\n",
       "      <td>6.877296</td>\n",
       "      <td>4.268438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.063568</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shortnam  africa  lat_abst  rich4    avexpr  logpgp95    logem4  asia  \\\n",
       "1       AGO     1.0  0.136667    0.0  5.363636  7.770645  5.634789   0.0   \n",
       "3       ARG     0.0  0.377778    0.0  6.386364  9.133459  4.232656   0.0   \n",
       "5       AUS     0.0  0.300000    1.0  9.318182  9.897972  2.145931   0.0   \n",
       "11      BFA     1.0  0.144444    0.0  4.454545  6.845880  5.634789   0.0   \n",
       "12      BGD     0.0  0.266667    0.0  5.136364  6.877296  4.268438   1.0   \n",
       "\n",
       "    loghjypl  baseco  \n",
       "1  -3.411248     1.0  \n",
       "3  -0.872274     1.0  \n",
       "5  -0.170788     1.0  \n",
       "11 -3.540459     1.0  \n",
       "12 -2.063568     1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import and select the data\n",
    "df4 = pd.read_stata('https://github.com/QuantEcon/QuantEcon.lectures.code/raw/master/ols/maketable4.dta')\n",
    "df4 = df4[df4['baseco'] == 1]\n",
    "\n",
    "df4.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acemoglu et al. (2001) use:\n",
    "\n",
    "* economic outcome: _logpgp95_ , log GDP per capita in 1995, adjusted for exchange rates\n",
    "* institution quality: _avexpr_ , an index of protection against expropriation on average over 1985-95\n",
    "* instrument variable: _logem4_ , settler mortality rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               logpgp95   R-squared:                       0.976\n",
      "Model:                         IV2SLS   Adj. R-squared:                  0.975\n",
      "Method:                     Two Stage   F-statistic:                       nan\n",
      "                        Least Squares   Prob (F-statistic):                nan\n",
      "Date:                Thu, 12 Sep 2019                                         \n",
      "Time:                        22:20:00                                         \n",
      "No. Observations:                  64                                         \n",
      "Df Residuals:                      63                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "avexpr         1.2468      0.026     47.531      0.000       1.194       1.299\n",
      "==============================================================================\n",
      "Omnibus:                        0.340   Durbin-Watson:                   2.052\n",
      "Prob(Omnibus):                  0.844   Jarque-Bera (JB):                0.474\n",
      "Skew:                          -0.152   Prob(JB):                        0.789\n",
      "Kurtosis:                       2.707   Cond. No.                         1.00\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyevre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\dyevre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\dyevre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.sandbox.regression.gmm as gmm\n",
    "\n",
    "model = gmm.IV2SLS(endog=df4['logpgp95'], exog=df4['avexpr'], instrument=df4['logem4'])\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
